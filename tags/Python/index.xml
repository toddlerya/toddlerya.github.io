<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on 不期速成日拱一卒</title>
    <link>https://toddlerya.github.io/tags/python/</link>
    <description>Recent content in Python on 不期速成日拱一卒</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 07 Jan 2018 12:24:53 +0000</lastBuildDate>
    
	<atom:link href="https://toddlerya.github.io/tags/python/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>微信跳一跳之线性回归算法优化</title>
      <link>https://toddlerya.github.io/post/%E5%BE%AE%E4%BF%A1%E8%B7%B3%E4%B8%80%E8%B7%B3%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95%E4%BC%98%E5%8C%96/</link>
      <pubDate>Sun, 07 Jan 2018 12:24:53 +0000</pubDate>
      
      <guid>https://toddlerya.github.io/post/%E5%BE%AE%E4%BF%A1%E8%B7%B3%E4%B8%80%E8%B7%B3%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95%E4%BC%98%E5%8C%96/</guid>
      <description>最近微信上线了一款小应用&amp;mdash;“跳一跳”，这个规则简单，让人上瘾的小游戏和2048一样魔性，朋友圈也是各路小伙伴各显神通：硬件流（树莓派+步进电机）、日天流（篡改http请求）、软件流（adb控制手机模拟点击）。
今天我们也来实践下，当然选择最顺手的Python来搞咯，直接找到开源项目wechat_jump_game进行优化改造。此项目有个pull request[优化]跑分17000+ 新增AI模块，机器人自主学习生成跳跃公式，看到AI我们就来了兴趣，只见过理论，还没有实践过，可以拿这个实践下。
这个pull request介绍如下： &amp;gt; 机器人精确采集跳跃结果并自主学习，使用线性回归方法 &amp;gt; 拟合出最优 [按压时间]-&amp;gt;[弹跳距离] 线性公式 Y =kX + b &amp;gt; 本优化无需修改config文件，可以适配所有手机，经过十次以上跳跃学习，机器人即可 &amp;gt; 模拟出相对稳定的线性公式。随着采集结果越多，跳跃也越精确，后期基本连续命中靶心。 &amp;gt; 理论上只要目标点获取无误，会一直跳下去。
工作两年多，一直在做服务端后台应用相关的测试，没接触过移动端测试呢，正好趁这次机会学习下怎么通过代码自动化控制安卓手机。 下面来动手试一下，找出下岗多年的MX3，充电开机。
第一次调试  安装好adb，配置好环境变量。 手机打开开发者模式，连接PC。 命令行测试是否连接成功: adb devices，手机弹出是否信任窗口，点击确定，已经链接成功。 测试一些adb命令是否正常: adb shell wm size，返回信息：Physical size: 1080x1800，完美。 通过virtualenv建立虚拟环境，安装项目所需的第三方库。 手机微信打开跳一跳，点击开始游戏。 运行wechat_jump_auto_ai.py，报错T_T&amp;hellip; 查看代码发现是截图部分操作不适配MX3，手动修改代码后成功截图运行 将 Python screenshot = screenshot.replace(b&#39;\r\n&#39;, b&#39;\n&#39;)  修改为 Python screenshot = screenshot.replace(b&#39;\r\r\n&#39;, b&#39;\n&#39;)   第二次调试 按照程序逻辑，运行十次之后即可采用线性回归算法学习得到的公式，根据已知距离得出按压时间，但实际结果却和一个弱智一样，2分就挂掉了&amp;hellip; 查看代码发现有个魔法数字要自己设置，程序根据这个数字进行截图计算误差:time.sleep(0.2)。
# 在跳跃落下的瞬间 摄像机移动前截图 这个参数要自己校调 time.sleep(0.2) pull_screenshot_temp() im_temp = Image.open(&#39;./autojump_temp.png&#39;) temp_piece_x, temp_piece_y = find_piece(im_temp) debug.</description>
    </item>
    
    <item>
      <title>50万Coding用户关系爬爬爬爬</title>
      <link>https://toddlerya.github.io/post/50%E4%B8%87coding%E7%94%A8%E6%88%B7%E5%85%B3%E7%B3%BB%E7%88%AC%E7%88%AC%E7%88%AC%E7%88%AC/</link>
      <pubDate>Sun, 29 Oct 2017 13:05:54 +0000</pubDate>
      
      <guid>https://toddlerya.github.io/post/50%E4%B8%87coding%E7%94%A8%E6%88%B7%E5%85%B3%E7%B3%BB%E7%88%AC%E7%88%AC%E7%88%AC%E7%88%AC/</guid>
      <description>今天我们继续来搞Coding数据~
从官方给出的数据我们知道目前Coding大概有50万注册用户
然后我们还能看到冒泡广场有很多热门用户
那么这些用户之间的关系是什么样子滴？
哪些用户是高冷吸粉狂人？
哪些用户是社交达人？
哪些用户是万年潜水独行侠？
50万Coding小伙伴的社交网络核心是哪位？
是否真的有50万用户？
带着这些疑问，我们开始撸代码！
先把项目地址贴下：https://github.com/toddlerya/AnalyzeCoding
爬虫算法分析设计： 如何获取全部用户信息 通过分析Coding网站, 我们发现有3个地方可以获取到用户数据信息：  冒泡广场: 每一条冒泡都有发布人，有些还有点赞人、打赏人、评论人
 热门用户：冒泡广场首页右侧有20个热门用户，这些用户是当前最活跃的用户，这些用户拥有比较多的粉丝和朋友。
 个人主页：用户的个人主页有一个标签页：关注，这里可以看到此用户关注了哪些人，被哪些人关注。
  现在就是开脑洞的时候啦！ 用户之间的关系分为三种：
 A关注B: A--&amp;gt;B A被B关注：A&amp;lt;--B A与B互相关注：A&amp;lt;--&amp;gt;B  这就是个有向图嘛！
六度分隔理论:
1967年，哈佛大学的心理学教授Stanley Milgram(1933-1984)想要描绘一个连结人与社区的人际连系网。做过一次连锁信实验，结果发现了“六度分隔”现象。简单地说：“你和任何一个陌生人之间所间隔的人不会超过六个，也就是说，最多通过六个人你就能够认识任何一个陌生人。”
思路渐渐清晰了，我们可以采用深度优先算法（Depth-First Search，简称DFS）
从A出发，找到A所有的好友（A1,A2,A3）记录为{A: [A1, A2, A3]}
从A1出发，找到A1所有的好友（A,A2-1,A3-1）记录为{A1: [A, A2-1, A3-1]}
从A2-1出发，找到A2-1所有的好友（A2-1-1）记录为{A2-1: [A2-1-1]}
从A3-1出发，找到A3-1所有的好友（A3-1-1）记录为{A3-1: [A3-1-1]}
从A2出发，找到A2所有的好友（A2-1）记录为{A2: [A2-1]}
……循环递归……
直到Z，Z同学没有任何好友，结束本次遍历爬取。
爬取过程中要注意，已经爬取过的人要跳过，否则会陷入无限循环中。
相关API  当前热门用户：https://coding.net/api/tweet/best_user 用户的朋友们：https://coding.net/api/user/friends/{用户全局唯一代号}?page=1&amp;amp;pageSize=20 用户的粉丝们：https://coding.net/api/user/followers/{用户全局唯一代号}?page=1&amp;amp;pageSize=20 用户个人信息详情：https://coding.net/api/user/key/{用户全局唯一代号}  代码设计实现 数据库设计 为了程序轻便，数据便于分享，我们决定使用Sqlite数据库。
上述分析过程中发送，用户的登录帐号是全局唯一的，不会重复的，我们以此字段作为主键且不允许为空， 还可以通过上述API获取用户的朋友、朋友的个数、用户的粉丝、粉丝的个数、用户详细信息，因此用户社交关系表设计如下：
CREATE TABLE IF NOT EXISTS coding_all_user ( global_key VARCHAR PRIMARY KEY NOT NULL, friends_count INTEGER, friends VARCHAR, followers_count INTEGER, followers VARCHAR )  用户个人信息详情表设计如下：</description>
    </item>
    
    <item>
      <title>利用Python解读十九大工作报告</title>
      <link>https://toddlerya.github.io/post/%E5%88%A9%E7%94%A8python%E8%A7%A3%E8%AF%BB%E5%8D%81%E4%B9%9D%E5%A4%A7%E5%B7%A5%E4%BD%9C%E6%8A%A5%E5%91%8A/</link>
      <pubDate>Sun, 22 Oct 2017 16:23:44 +0000</pubDate>
      
      <guid>https://toddlerya.github.io/post/%E5%88%A9%E7%94%A8python%E8%A7%A3%E8%AF%BB%E5%8D%81%E4%B9%9D%E5%A4%A7%E5%B7%A5%E4%BD%9C%E6%8A%A5%E5%91%8A/</guid>
      <description>关键词: Python、wordcloud、jieba、matplotlib、词云、分词
 前几天的召开的十九大，习近平讲了三小时的三万字工作报告究竟讲了些什么内容呢，我们用Python来一次数据分析看看究竟讲了哪些内容。
主要思路： + 通过jieba分词对工作报告进行切词，清洗，词频统计。 + 通过wordcloud对切词统计结果进行可视化展示。
jieba分词利器 特点  支持三种分词模式：  精确模式，试图将句子最精确地切开，适合文本分析； 全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义； 搜索引擎模式，在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。
   jieba项目地址：https://github.com/fxsjy/jieba
遇到的问题以及解决办法： 1. 无法匹配最新的词汇 我们采用精确模式进行分词，但是遇到一些词汇在jieba的默认词库没有，所以要根据十九大进行一些定制词库，加载到jieba词库:
import jieba cpc_dict_path = u&#39;user_dict/cpc_dictionary.txt&#39; jieba.load_userdict(cpc_dict_path) # 加载针对全国人民代表大会的分词词典  2. 匹配到了各种符号、空格 切词后统计词频发现有很多标点符号、空格，这些内容我们可以使用正则匹配法进行过滤，u&#39;[\u4e00-\u9fa5]+&#39;匹配所有中文字符，舍弃未命中内容:
import re goal_word = &#39;&#39;.join(re.findall(u&#39;[\u4e00-\u9fa5]+&#39;, seg)).strip() # 过滤所有非中文字符内容  3. 匹配到了很多停词 切词后统计词频发现有很多停词，例如：“的”、“和”、“而且”…… 这种问题肯定不止我遇到了，所以直接去找前人整理好的停词词库即可，通过匹配停词来进行过滤：
stop_words_path = u&#39;user_dict/stopword.txt&#39; with open(stop_words_path) as sf: st_content = sf.readlines() stop_words = [line.strip().decode(&#39;utf-8&#39;) for line in st_content] # 将读取的数据都转为unicode处理 if len(goal_word) !</description>
    </item>
    
    <item>
      <title>关于NebulaSolarDash</title>
      <link>https://toddlerya.github.io/post/%E5%85%B3%E4%BA%8Enebulasolardash/</link>
      <pubDate>Wed, 10 May 2017 22:06:10 +0000</pubDate>
      
      <guid>https://toddlerya.github.io/post/%E5%85%B3%E4%BA%8Enebulasolardash/</guid>
      <description>2017年的5月1日，三天假期，闭门造了个轮子 写这个工具的目的是为了解决工作问题。 个人工作生产环境无法连接互联网，也没有自建的yum源等，手头又有很多服务器需要进行监控，使用现有的开源方案安装部署是个问题， 各种依赖组件包需要挨个安装，很麻烦，所以想找一款依赖较少部署简单的分布式服务器资源监控工具，找来找去没找到，索性自己动手写一个。 我的本职工作是测试，所以就用最熟悉的Python来写吧，第一次写web应用，先做出来再边学边优化吧。
工具分为客户端和服务端两部分： 服务端使用了bottle来作为web框架，echarts来渲染生成图表； 客户端使用Python原生类库采集服务器资源，客户端采集数据部分代码参考了pyDash
效果如下 项目链接链接 NebulaSolarDash
2017年05月10日 于 南京
Email
GitHub</description>
    </item>
    
    <item>
      <title>Scrapy爬取Coding冒泡广场</title>
      <link>https://toddlerya.github.io/post/scrapy%E7%88%AC%E5%8F%96coding%E5%86%92%E6%B3%A1%E5%B9%BF%E5%9C%BA/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://toddlerya.github.io/post/scrapy%E7%88%AC%E5%8F%96coding%E5%86%92%E6%B3%A1%E5%B9%BF%E5%9C%BA/</guid>
      <description>项目地址: https://github.com/toddlerya/learn_scrapy I. Coding的冒泡广场 CODING 是国内专业的一站式云端软件服务平台，Coding.net 为开发者提供了免费的基础服务，包括但不限于 Git 代码托管，项目管理，Pages 服务，代码质量管理。您可以在 Coding.net 一站完成代码及代码质量，项目及项目人员的管理，Coding.net 让开发变得前所未有的敏捷和简单。
其中Coding有一个冒泡的社交功能&amp;ndash; 冒泡广场，比较像微博，会有很多程序员的日常吐槽，分享等，比如这样：
这里面的数据属性非常丰富，每一条冒泡都具有如下属性：
1. 爬虫分析 爬虫的基本原则是能使用API接口，绝不解析html页面，恰巧这个网站的API很好用。
+ 对这个网站的API进行了基本的分析：html https://coding.net/api/tweet/public_tweets?size=20&amp;amp;sort=time&amp;amp;filter=true&amp;amp;last_time=1504876265000
 分析发现只需提交size和filter参数即可：
 filter=true为只获取精华冒泡，false为获取全量，当然是全量啦！ size为最近发表的多少条冒泡信息
  因此最终的get 请求为： https://coding.net/api/tweet/public_tweets?size=20&amp;amp;filter=false
  2. 这里有两个注意事项  网站的rebots.txt设置了规则，禁止爬取Disallow: /api/*，我们只是做个小实验，不进行大规模的爬取，因此需要修改下Scrapy项目的settings.py配置(不守规矩~):
# Obey robots.txt rules ROBOTSTXT_OBEY = False  size参数如果太大会导致HTTP访问超时，Scrapy报错中止，需要在请求发起时修改Request.meta的参数，见官方文档：DOWNLOAD_TIMEOUT
[scrapy.downloadermiddlewares.retry] DEBUG: Retrying &amp;lt;GET https://coding.net/api/tweet/public_tweets?size=100000&amp;amp;filter=false&amp;gt; (failed 1 times): 504 Gateway Time-out   2017年09月11日 于 南京
Email
GitHub</description>
    </item>
    
  </channel>
</rss>