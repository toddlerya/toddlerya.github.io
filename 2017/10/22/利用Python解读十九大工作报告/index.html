<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>利用Python解读十九大工作报告 | 小明挖坑的地方</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="关键词: Python、wordcloud、jieba、matplotlib、词云、分词  前几天的召开的十九大，习近平讲了三小时的三万字工作报告究竟讲了些什么内容呢，我们用Python来一次数据分析看看究竟讲了哪些内容。主要思路：  通过jieba分词对工作报告进行切词，清洗，词频统计。 通过wordcloud对切词统计结果进行可视化展示。   jieba分词利器特点 支持三种分词模式： 精确">
<meta name="keywords" content="Python">
<meta property="og:type" content="article">
<meta property="og:title" content="利用Python解读十九大工作报告">
<meta property="og:url" content="http://yoursite.com/2017/10/22/利用Python解读十九大工作报告/index.html">
<meta property="og:site_name" content="小明挖坑的地方">
<meta property="og:description" content="关键词: Python、wordcloud、jieba、matplotlib、词云、分词  前几天的召开的十九大，习近平讲了三小时的三万字工作报告究竟讲了些什么内容呢，我们用Python来一次数据分析看看究竟讲了哪些内容。主要思路：  通过jieba分词对工作报告进行切词，清洗，词频统计。 通过wordcloud对切词统计结果进行可视化展示。   jieba分词利器特点 支持三种分词模式： 精确">
<meta property="og:image" content="http://ovzv5zg5e.bkt.clouddn.com/001/20171022-ca2e12dc.png">
<meta property="og:image" content="http://ovzv5zg5e.bkt.clouddn.com/001/20171022-637b8f8f.png">
<meta property="og:updated_time" content="2017-12-13T13:59:32.426Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="利用Python解读十九大工作报告">
<meta name="twitter:description" content="关键词: Python、wordcloud、jieba、matplotlib、词云、分词  前几天的召开的十九大，习近平讲了三小时的三万字工作报告究竟讲了些什么内容呢，我们用Python来一次数据分析看看究竟讲了哪些内容。主要思路：  通过jieba分词对工作报告进行切词，清洗，词频统计。 通过wordcloud对切词统计结果进行可视化展示。   jieba分词利器特点 支持三种分词模式： 精确">
<meta name="twitter:image" content="http://ovzv5zg5e.bkt.clouddn.com/001/20171022-ca2e12dc.png">
  
    <link rel="alternate" href="/atom.xml" title="小明挖坑的地方" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">小明挖坑的地方</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">但行好事，莫问前程。</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Suche"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-利用Python解读十九大工作报告" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/10/22/利用Python解读十九大工作报告/" class="article-date">
  <time datetime="2017-10-22T08:23:44.000Z" itemprop="datePublished">2017-10-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/数据分析/">数据分析</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      利用Python解读十九大工作报告
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>关键词: Python、wordcloud、jieba、matplotlib、词云、分词</p>
</blockquote>
<p>前几天的召开的十九大，习近平讲了三小时的三万字工作报告究竟讲了些什么内容呢，我们用Python来一次数据分析看看究竟讲了哪些内容。<br>主要思路：</p>
<ul>
<li>通过<code>jieba</code>分词对工作报告进行切词，清洗，词频统计。</li>
<li>通过<code>wordcloud</code>对切词统计结果进行可视化展示。</li>
</ul>
<hr>
<h2 id="jieba分词利器"><a href="#jieba分词利器" class="headerlink" title="jieba分词利器"></a>jieba分词利器</h2><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul>
<li>支持三种分词模式：<ul>
<li>精确模式，试图将句子最精确地切开，适合文本分析；</li>
<li>全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义；</li>
<li>搜索引擎模式，在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。  </li>
</ul>
</li>
</ul>
<p>jieba项目地址：<a href="https://github.com/fxsjy/jieba" target="_blank" rel="noopener">https://github.com/fxsjy/jieba</a></p>
<h3 id="遇到的问题以及解决办法："><a href="#遇到的问题以及解决办法：" class="headerlink" title="遇到的问题以及解决办法："></a>遇到的问题以及解决办法：</h3><h4 id="1-无法匹配最新的词汇"><a href="#1-无法匹配最新的词汇" class="headerlink" title="1. 无法匹配最新的词汇"></a>1. 无法匹配最新的词汇</h4><p>我们采用精确模式进行分词，但是遇到一些词汇在jieba的默认词库没有，所以要根据十九大进行一些<a href="https://github.com/toddlerya/AnalyzeNPC/blob/master/user_dict/cpc_dictionary.txt" target="_blank" rel="noopener"><code>定制词库</code></a>，加载到<code>jieba</code>词库:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line">cpc_dict_path = <span class="string">u'user_dict/cpc_dictionary.txt'</span></span><br><span class="line">jieba.load_userdict(cpc_dict_path)  <span class="comment"># 加载针对全国人民代表大会的分词词典</span></span><br></pre></td></tr></table></figure></p>
<h4 id="2-匹配到了各种符号、空格"><a href="#2-匹配到了各种符号、空格" class="headerlink" title="2. 匹配到了各种符号、空格"></a>2. 匹配到了各种符号、空格</h4><p>切词后统计词频发现有很多标点符号、空格，这些内容我们可以使用正则匹配法进行过滤，<code>u&#39;[\u4e00-\u9fa5]+&#39;</code>匹配所有中文字符，舍弃未命中内容:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">goal_word = <span class="string">''</span>.join(re.findall(<span class="string">u'[\u4e00-\u9fa5]+'</span>, seg)).strip()  <span class="comment"># 过滤所有非中文字符内容</span></span><br></pre></td></tr></table></figure></p>
<h4 id="3-匹配到了很多停词"><a href="#3-匹配到了很多停词" class="headerlink" title="3. 匹配到了很多停词"></a>3. 匹配到了很多停词</h4><p>切词后统计词频发现有很多<code>停词</code>，例如：“的”、“和”、“而且”……<br>这种问题肯定不止我遇到了，所以直接去找前人整理好的<a href="https://github.com/toddlerya/AnalyzeNPC/blob/master/user_dict/stopword.txt" target="_blank" rel="noopener"><code>停词词库</code></a>即可，通过匹配停词来进行过滤：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">stop_words_path = <span class="string">u'user_dict/stopword.txt'</span></span><br><span class="line"><span class="keyword">with</span> open(stop_words_path) <span class="keyword">as</span> sf:</span><br><span class="line">    st_content = sf.readlines()</span><br><span class="line">stop_words = [line.strip().decode(<span class="string">'utf-8'</span>) <span class="keyword">for</span> line <span class="keyword">in</span> st_content]  <span class="comment"># 将读取的数据都转为unicode处理</span></span><br><span class="line"><span class="keyword">if</span> len(goal_word) != <span class="number">0</span> <span class="keyword">and</span> <span class="keyword">not</span> stop_words.__contains__(goal_word):</span><br><span class="line">    ......</span><br></pre></td></tr></table></figure></p>
<hr>
<h2 id="wordcloud词云神器"><a href="#wordcloud词云神器" class="headerlink" title="wordcloud词云神器"></a>wordcloud词云神器</h2><p>使用<code>wordcloud</code>生成词云，支持进行各种个性化设置，很好很强大。<br>项目地址：<a href="https://github.com/amueller/word_cloud" target="_blank" rel="noopener">https://github.com/amueller/word_cloud</a></p>
<h3 id="遇到的问题及解决办法："><a href="#遇到的问题及解决办法：" class="headerlink" title="遇到的问题及解决办法："></a>遇到的问题及解决办法：</h3><h4 id="1-wordcloud默认不支持显示中文"><a href="#1-wordcloud默认不支持显示中文" class="headerlink" title="1. wordcloud默认不支持显示中文"></a>1. wordcloud默认不支持显示中文</h4><p>不进行处理，直接使用<code>wordcloud</code>绘制词云，显示效果如下，中文都是小方框：<br><!-- ![](/images/20171022-ca2e12dc.png) --><br><img src="http://ovzv5zg5e.bkt.clouddn.com/001/20171022-ca2e12dc.png" alt=""><br>善用搜索引擎，查到问题原因根本在于<font color="red"><b>wordcloud的默认字体不支持中文</b></font>。<br>解决方案基本分为两种：</p>
<ul>
<li>方案1：修改<code>wordcloud</code>库文件，增加字体环境变量：<a href="https://zhuanlan.zhihu.com/p/20436581" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/20436581</a></li>
<li>方案2：在每个项目代码中创建<code>WordCloud</code>对象时指定字体文件：<a href="http://blog.csdn.net/xiemanr/article/details/72796739" target="_blank" rel="noopener">http://blog.csdn.net/xiemanr/article/details/72796739</a>  </li>
</ul>
<p>个人认为<code>方案2</code>更好一些，提高了代码的可移植性，同时避免了升级<code>wordcloud</code>库导致代码失效的风险。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">font = os.path.abspath(<span class="string">'assets/msyh.ttf'</span>)</span><br><span class="line">wc = WordCloud(collocations=<span class="keyword">False</span>, font_path=font, width=<span class="number">3600</span>, height=<span class="number">3600</span>, margin=<span class="number">2</span>)</span><br></pre></td></tr></table></figure></p>
<p>设置好字体后显示效果如下，已经基本实现了我们的目标：<br><!-- ![](/images/20171022-637b8f8f.png) --><br><img src="http://ovzv5zg5e.bkt.clouddn.com/001/20171022-637b8f8f.png" alt="">  </p>
<hr>
<p>项目地址：<a href="https://github.com/toddlerya/AnalyzeNPC" target="_blank" rel="noopener">AnalyzeNPC</a><br>核心代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># author: toddler</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cut_analyze</span><span class="params">(input_file)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    :param input_file: 输入带切词分析的文本路径</span></span><br><span class="line"><span class="string">    :return: (list1, list2) list1切词处理后的列表结果, list2输出切词处理排序后的词频结果, 列表-元祖嵌套结果</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    cpc_dict_path = <span class="string">u'user_dict/cpc_dictionary.txt'</span></span><br><span class="line">    stop_words_path = <span class="string">u'user_dict/stopword.txt'</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> open(input_file) <span class="keyword">as</span> f:</span><br><span class="line">        content = f.read()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> open(stop_words_path) <span class="keyword">as</span> sf:</span><br><span class="line">        st_content = sf.readlines()</span><br><span class="line"></span><br><span class="line">    jieba.load_userdict(cpc_dict_path)  <span class="comment"># 加载针对全国人民代表大会的分词词典</span></span><br><span class="line"></span><br><span class="line">    stop_words = [line.strip().decode(<span class="string">'utf-8'</span>) <span class="keyword">for</span> line <span class="keyword">in</span> st_content]  <span class="comment"># 将读取的数据都转为unicode处理</span></span><br><span class="line"></span><br><span class="line">    seg_list = jieba.cut(content, cut_all=<span class="keyword">False</span>)  <span class="comment"># 精确模式</span></span><br><span class="line"></span><br><span class="line">    filter_seg_list = list()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> seg <span class="keyword">in</span> seg_list:</span><br><span class="line">        goal_word = <span class="string">''</span>.join(re.findall(<span class="string">u'[\u4e00-\u9fa5]+'</span>, seg)).strip()  <span class="comment"># 过滤所有非中文字符内容</span></span><br><span class="line">        <span class="keyword">if</span> len(goal_word) != <span class="number">0</span> <span class="keyword">and</span> <span class="keyword">not</span> stop_words.__contains__(goal_word):  <span class="comment"># 过滤分词结果中的停词内容</span></span><br><span class="line">            <span class="comment"># filter_seg_list.append(goal_word.encode('utf-8'))  # 将unicode的文本转为utf-8保存到列表以备后续处理</span></span><br><span class="line">            filter_seg_list.append(goal_word)</span><br><span class="line"></span><br><span class="line">    seg_counter_all = Counter(filter_seg_list).most_common()  <span class="comment"># 对切词结果按照词频排序</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># for item in seg_counter_all:</span></span><br><span class="line">    <span class="comment">#     print "词语: &#123;0&#125; - 频数: &#123;1&#125;".format(item[0].encode('utf-8'), item[1])</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> filter_seg_list, seg_counter_all</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    input_file_path = <span class="string">u'input_file/nighteen-cpc.txt'</span></span><br><span class="line">    cut_data, sort_data = cut_analyze(input_file=input_file_path)</span><br><span class="line">    font = <span class="string">r'E:\Codes\National_Congress_of_ CPC\assets\msyh.ttf'</span></span><br><span class="line">    wc = WordCloud(collocations=<span class="keyword">False</span>, font_path=font, width=<span class="number">3600</span>, height=<span class="number">3600</span>, margin=<span class="number">2</span>)</span><br><span class="line">    wc.generate_from_frequencies(dict(sort_data))</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.imshow(wc)</span><br><span class="line">    plt.axis(<span class="string">'off'</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></p>
<hr>
<p>2017年10月22日 于 南京<br><a href="toddlerya@qq.com">Email</a><br><a href="https://github.com/toddlerya" target="_blank" rel="noopener">GitHub</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/10/22/利用Python解读十九大工作报告/" data-id="cjb54u0a80006d8g0genxkvxt" class="article-share-link">Teilen</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/">Python</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/10/29/50万Coding用户关系爬爬爬爬/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Neuer</strong>
      <div class="article-nav-title">
        
          50万Coding用户关系爬爬爬爬
        
      </div>
    </a>
  
  
    <a href="/2017/09/11/Scrapy爬取Coding冒泡广场/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Älter</strong>
      <div class="article-nav-title">Scrapy爬取Coding冒泡广场</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Kategorien</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/工具/">工具</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据分析/">数据分析</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/造轮子/">造轮子</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vim/">vim</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/工具/">工具</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/爬虫/">爬虫</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/资源监控/">资源监控</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Python/" style="font-size: 20px;">Python</a> <a href="/tags/vim/" style="font-size: 10px;">vim</a> <a href="/tags/工具/" style="font-size: 15px;">工具</a> <a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a> <a href="/tags/资源监控/" style="font-size: 10px;">资源监控</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archiv</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">May 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">letzter Beitrag</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/10/29/50万Coding用户关系爬爬爬爬/">50万Coding用户关系爬爬爬爬</a>
          </li>
        
          <li>
            <a href="/2017/10/22/利用Python解读十九大工作报告/">利用Python解读十九大工作报告</a>
          </li>
        
          <li>
            <a href="/2017/09/11/Scrapy爬取Coding冒泡广场/">Scrapy爬取Coding冒泡广场</a>
          </li>
        
          <li>
            <a href="/2017/09/08/Pythoner的vim/">Pythoner的vim</a>
          </li>
        
          <li>
            <a href="/2017/05/10/关于NebulaSolarDash/">关于NebulaSolarDash</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 evi1小明<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>